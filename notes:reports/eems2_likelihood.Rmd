---
title: "Finding a good likelihood function for eems2"
output: html_document
---

## simulating under the model

First, let's simulate data under the approximate constant one deme coalescent model.

The number of blocks shared between two individuals (greater than L) is approximately Poisson. Next, we need to compute the pdf of length of each block (conditional on l > L).
$$p(l|l>L) = \begin{cases} 0, & \mbox{if } l\mbox{ is less or equal to L} \\ p(l)/p(l>L) , & \mbox{if } l\mbox{ greater than L} \end{cases}$$
$p(l) = \int_0^{\infty} p(l|t)p(t) dt$ from the law of total probability and $p(l|t) = t^2 4 r^2 l e^{-2trl}$ according to coalescent theory. Furthermore, we are assuming a constant pop. size so $p(t) = (1/N)e^{-t/N}$. Therefore if l >L,
$$p(l|l>L) = \frac{8 l N^2 r^2 (1 + 2 L N r)^2}{(1 + 2 l N r)^3 (1 + 4 L N r)}$$

Which looks something like this: 
```{r, echo=FALSE}
# l is in base pairs
# L is in base pairs
# r is recombination rate per basepair
p_l <- function(l, L=2e6, r=1e-8, N=1e4){
  if (l < L){
    return(0)
  }
  return( ((8*l*N*N*r*r)*(1 + 2*L*N*r)^2)/((1 + 4*L*N*r)*(1 + 2*l*N*r)^3) )
}
l = seq(2e6, 10e6, 1e5)
f = unlist(lapply(l, FUN=p_l))
plot(l, f, ylab = "p(l|l>L)", main = "L=2e6, r=1e-8")
```

This plot of $p(l|l>L)$ looks like an exponential distribution.

For simplicity, let's assume a simple exponential distribution for $p(l|l>L)$.
```{r}
simExact <- function(nBlocks, nreps){
  X = rpois(nreps, lambda = nBlocks)
  
  # Let's assume each exponential has mean 1 
  # Y represents the total length of shared segments
  Y = lapply(X, FUN = function(X) sum(rexp(X,1)))
  
  # assume genome size is 1e2. The value below represents the distance.
  return(1e2-unlist(Y))
}
```


Here, I vary the mean number of blocks people share. 
```{r}
hist(simExact(nBlocks = 1, nreps = 10000), n =100)
hist(simExact(nBlocks = 3, nreps = 10000), n =100)
hist(simExact(nBlocks = 10, nreps = 10000), n =100)
```

You can see, as the number of blocks shared by individuals increases, the distribution gets more normal. How many IBD blocks do you expect in the W-F model? Palarama, 2012 show that for a panmitic population
$$\lambda \approx \int_u^{\infty} \frac{p(l)}{l}$$

```{r, echo=FALSE}
N = seq(1e2, 1e4, by=100)
# in centimograns
r=1e-8
L = 2e6
plot(N, 3e9*(2*N*r)/(1+2*N*L*r)^2, xlab = "N", ylab = "expected number of segments", main = "2cM or greater")
```

The number of shared IBD blocks is large if the population is very small but small otherwise. In EEMS2, we are looking at structured populations so the number of shared IBD blocks are very small. This can be shown by looking at the analysis of the POPRES data of Ralph & Coop, 2008 where the number of blocks shared by pairs are around 0.5 (so even a bigger problem). 

## The Wishart approximation
Currently, in EEMS2, we assume a Wishart likelihood. Let's investigate below whether the Wishart approximation is a decent one.

### Generating Dobs for only two samples
```{r}
# basis for contrats
L = matrix(nrow=1, ncol=2, 0)
L[1,1] = 1
L[1,2] = -1

nreps = 1000
Wobs = rep(0, nreps)
for (i in 1:nreps){
  Dobs = matrix(nrow=2, ncol=2, 0)
  Dobs[1,2] = Dobs[2,1] = simExact(nBlocks=3, nreps = 1)
  Wobs[i] = -L%*%Dobs%*%t(L)
}
hist(Wobs, n = 100, xlab = "observed", main = "")
```

This is somewhat troubling because there is a hard boundary that the Wishart likelihood probably cannot accomedate. Let's find out below.


### simulating from the Wishart model
```{r}
D = matrix(nrow=2, ncol=2, 0)
D[1,2] = D[2,1] = 0.99
W = -L%*%D%*%t(L)
n = 1000
# df estimated from the data from a run of EEMS2
df = 60000
X = rWishart(n, df, W)
hist(X, xlab = "expected", main = "", 100)

```

So, as you can see, the Wishart approximation is not so good. In this example, it looks like a normal distribution and this has problems with the observed summary statistic, mainly because of the hard-boundary issue.

## How do we fix this issue? 

Here is a simple idea: Use the number of shared IBD blocks as a summary statistic and assume a composite likelihood. The number of blocks has lower variance then the total sharing. In addition, we no longer have to estimate the degrees of freedom. Furthermore, the number of IBD blocks is easier to infer than the total length of blocks. My intuition is that inferring IBD essentially boils down to finding segments with long streches of homogzyosity and it is much easier to say that a particular strech longer than u cM than to stay this strech is exactly x cM long. However, it's not completely clear whether the number of shared IBD blocks is less/more/equally informative compared to the total length of shared segments. 

### The composite likelihood model
$$\hat{\lambda_{i,j}} \sim Pois(\lambda_{i,j})$$ In other words $p(\hat{\lambda_{i,j}}|\lambda_{i,j})$ is Poisson. Furthermore, $\lambda$ is calculated assuming a demographic model $\theta$.
Then
$$l(\theta) = \prod_{i<j} p(\hat{\lambda_{i,j}}|\lambda_{i,j})$$
For estimating the mle, this works quite well according to personal correspondence with Pier Palamara. Furthermore, from a notable paper on IBD and demography, Ralph & Coop say:

> Suppose we are looking at IBD blocks shared between any of a set of np pairs of individuals, and assume that N(y), the number of observed IBD blocks shared between any of those pairs of length at least y, is Poisson distributed with mean npM(y)

Let's investigate how well this likelihood fits the data for ourselves.

First, let's investigate IBD sharing in a one deme population with 2N=2,000 and number of sampled haploids = 160 (so large sample size)
```{r, echo=FALSE}
file = "data/eems2_likelihood/l_1.3e8_N_1000_mu_1.25e-8_r_1e-8_1D.N.2000000"
sim = read.csv(file, sep = " ", header=FALSE)
sim[,161] = NULL
sim = as.matrix(sim)
pairwise = sim[upper.tri(sim)]
m = mean(pairwise)
n = length(pairwise)
hist(rpois(lambda=m, n), 20, freq=FALSE, col=rgb(1,0,0,0.5), main = "within sharing", xlab = "number of shared segments")
hist(pairwise,20, freq=FALSE,col=rgb(0,0,1,0.5), add=TRUE)
legend("topright", c("poisson approx", "empirical data", "overlap"), fill=c(rgb(1,0,0,0.5), rgb(0,0,1,0.5), rgb(1,0,1,1)))

```

Here is a two deme model with constant migration. I set 2N = 2000, and m = 0.01 and haploids = 80. Let's investiage whether the within sharing and the between sharing statistic follows the composite likelihood. The statistic here is defined as the number of IBD segments greater than 2cM.

```{r, echo=FALSE}
file = "data/eems2_likelihood/l_1.3e8_N_1000_m_0.01_mu_1.25e-8_r_1e-8_2D.N.2000000"
sim = read.csv(file, sep = " ", header=FALSE)
sim[,81] = NULL
sim = as.matrix(sim)
diag(sim) = max(sim)
pop1 = sim[1:40, 1:40]
pop2 = sim[41:80, 41:80]
within_sharing = c(pop1[upper.tri(pop1)], pop2[upper.tri(pop2)])

m1 = mean(within_sharing)

n1 = length(within_sharing)
hist(rpois(lambda=m1, n1), 20, freq=FALSE, col=rgb(1,0,0,0.5), main = "within sharing", xlab = "number of shared segments")
hist(within_sharing,20, freq=FALSE,col=rgb(0,0,1,0.5), add=TRUE)
legend("topright", c("poisson approx", "empirical data", "overlap"), fill=c(rgb(1,0,0,0.5), rgb(0,0,1,0.5), rgb(1,0,1,1)))

```

Now, the between sharing

```{r, echo=FALSE}
betw_sharing = sim[1:40, 41:80]
m2 = mean(betw_sharing)
n2 = length(betw_sharing)
hist(rpois(lambda=m2, n2), 20, freq=FALSE, col=rgb(1,0,0,0.5), main = "between sharing", xlab = "number of shared segments")
hist(betw_sharing,20, freq=FALSE,col=rgb(0,0,1,0.5), add=TRUE)
legend("topright", c("poisson approx", "empirical data", "overlap"), fill=c(rgb(1,0,0,0.5), rgb(0,0,1,0.5), rgb(1,0,1,1)))
```

## empirical data from POPRES

### Fit of Poisson

```{r, echo=FALSE, cache=TRUE}
library(data.table)
ibd_blocklens = read.csv("data/coop_popres/ibd-blocklens.csv")
ibd_labels = read.csv("data/coop_popres/ibd-pop-info.csv")

# in centimorgan
cutOff = 3

# apply cutoff and do it and need to combine across chromosomes

italy_subjects = ibd_labels$SUBJID[which(ibd_labels$COUNTRY_SELF == "Italy")]
uk_subjects = ibd_labels$SUBJID[which(ibd_labels$COUNTRY_SELF == "United Kingdom")]
 
within_uk = ibd_blocklens[(is.element(ibd_blocklens$id1, uk_subjects) & is.element(ibd_blocklens$id2, uk_subjects)),]
within_uk$maplen[within_uk$maplen < cutOff] = 0
within_uk$maplen[within_uk$maplen >= cutOff] = 1
within_uk = data.table(within_uk)
N = within_uk[, list(maplen = sum(maplen), chrom = sum(chrom)), by = list(id1, id2)]
hist(rpois(lambda=mean(N$maplen), length(N$maplen)), col=rgb(1,0,0,0.5), freq=FALSE, xlab = "Number of blocks", main = "within UK > 3cM", ylim=c(0,1), breaks=seq(-0.5, 8.5, length= 10))
hist(N$maplen, xlab = "Number of blocks", freq=FALSE,col=rgb(0,0,1,0.5), add=T, breaks=seq(-0.5, 20.5, length= 22))
legend("topright", c("poisson approx", "empirical data"), fill=c(rgb(1,0,0,0.5), rgb(0,0,1,0.5)))
N_uk = N$maplen

within_italy = ibd_blocklens[(is.element(ibd_blocklens$id1, italy_subjects) & is.element(ibd_blocklens$id2, italy_subjects)),]
within_italy$maplen[within_italy$maplen < cutOff] = 0
within_italy$maplen[within_italy$maplen >= cutOff] = 1
within_italy = data.table(within_italy)
N = within_italy[, list(maplen = sum(maplen), chrom = sum(chrom)), by = list(id1, id2)]
hist(rpois(lambda=mean(N$maplen), length(N$maplen)), col=rgb(1,0,0,0.5), xlab = "Number of blocks", main = "within Italy > 3cM", ylim=c(0,10000), breaks=seq(-0.5, 8.5, length= 10))
hist(N$maplen, xlab = "Number of blocks", main = "> 2cM",col=rgb(0,0,1,0.5), add=T, breaks=seq(-0.5, 20.5, length= 22))
legend("topright", c("poisson approx", "empirical data"), fill=c(rgb(1,0,0,0.5), rgb(0,0,1,0.5)))
N_italy = N$maplen

uk_italy = ibd_blocklens[(is.element(ibd_blocklens$id1, uk_subjects) & is.element(ibd_blocklens$id2, italy_subjects)),]
uk_italy$maplen[uk_italy$maplen < cutOff] = 0
uk_italy$maplen[uk_italy$maplen >= cutOff] = 1
uk_italy = data.table(uk_italy)
N = uk_italy[, list(maplen = sum(maplen), chrom = sum(chrom)), by = list(id1, id2)]
hist(rpois(lambda=mean(N$maplen), length(N$maplen)), col=rgb(1,0,0,0.5), xlab = "Number of blocks", main = "between Italy and UK > 3cM", ylim=c(0,10000), breaks=seq(-0.5, 8.5, length= 10))
hist(N$maplen, xlab = "Number of blocks", main = "> 3M",col=rgb(0,0,1,0.5), add=T, breaks=seq(-0.5, 20.5, length= 22))
legend("topright", c("poisson approx", "empirical data"), fill=c(rgb(1,0,0,0.5), rgb(0,0,1,0.5)))
N_uk_italy = N$maplen

```

We can see that the overdispersion is still there in the empirical data.


## Correcting for over-dispersion

```{r, echo=FALSE}
par(mfrow=c(1,1))
ropois <- function(m, v, n){
  p = (v-m)/v
  r = (m*m) / (v-m)
  return(rnbinom(prob=p, size=r, n=n))
}
data = ropois(m=mean(N_italy), v = var(N_italy), length(N_italy))
hist(data, col=rgb(1,0,0,0.5), xlab = "Number of blocks", main = "within Italy > 2cM", ylim=c(0,10000), breaks=seq(-0.5, max(data)+0.5))
hist(N_italy, xlab = "Number of blocks", main = "> 3cM",col=rgb(0,0,1,0.5), add=T, breaks=seq(-0.5, 20.5, length= 22))
legend("topright", c("negative binomial approx", "empirical data"), fill=c(rgb(1,0,0,0.5), rgb(0,0,1,0.5)))

```

I just did some moment matching with the negative binomial but this didn't work well.


### investigating correlations

Let's investigate correlations within the UK IBD data. Here I plot a random sample of 20,000 points versus another (w/o replacement).

```{r, echo=FALSE}
par(mfrow=c(3,3), mar=c(1,1,1,1))
for (i in 1:9){
    my_sample = N_uk[sample(1:length(N_uk), 40000, replace=FALSE)]
    x = my_sample[1:20000]
    y = my_sample[20001:40000]
    plot(x,y, xaxt='n', yaxt='n', main = paste("correlation coeff: ", round(cor(x,y, method="pearson"), 5)), xlim = c(0,10), ylim = c(0,10))
}

```

Let's do this many times and plot the histogram.
```{r, echo=FALSE}
par(mfrow=c(1,1))
nreps = 1000
corrs = rep(0, nreps)
for (i in 1:nreps){
    my_sample = N_uk[sample(1:length(N_uk), 40000, replace=FALSE)]
    x = my_sample[1:20000]
    y = my_sample[20001:40000]
    corrs[i] = round(cor(x,y, method="pearson"), 5)
}
hist(corrs, xlab = "correlations", main = "> 3cM")

```